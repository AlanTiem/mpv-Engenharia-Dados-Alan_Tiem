{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da07b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "from pyspark.sql.functions import col, count, countDistinct, isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f48a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de Datasets\n",
    "\n",
    "datasets = {\n",
    "    \"orders\": \"dbfs:/Workspace/dados_mpv/olist_orders_dataset.csv\",\n",
    "    \"order_items\": \"dbfs:/Workspace/dados_mpv/olist_order_items_dataset.csv\",\n",
    "    \"customers\": \"dbfs:/Workspace/dados_mpv/olist_customers_dataset.csv\",\n",
    "    \"products\": \"dbfs:/Workspace/dados_mpv/olist_products_dataset.csv\",\n",
    "    \"sellers\": \"dbfs:/Workspace/dados_mpv/olist_sellers_dataset.csv\",\n",
    "    \"reviews\": \"dbfs:/Workspace/dados_mpv/olist_order_reviews_dataset.csv\",\n",
    "    \"payments\": \"dbfs:/Workspace/dados_mpv/olist_order_payments_dataset.csv\",\n",
    "    \"geolocation\": \"dbfs:/Workspace/dados_mpv/olist_geolocation_dataset.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351776ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para análise de qualifidade\n",
    "\n",
    "def qualidade_colunas(df, nome_dataset):\n",
    "    print(f\"=== Dataset: {nome_dataset} ===\")\n",
    "    total = df.count()\n",
    "    for col_name in df.columns:\n",
    "        n_null = df.filter(col(col_name).isNull() | isnan(col(col_name))).count()\n",
    "        n_distinct = df.select(col_name).distinct().count()\n",
    "        print(f\"Coluna: {col_name}\")\n",
    "        print(f\" - Valores ausentes: {n_null} ({n_null/total*100:.2f}%)\")\n",
    "        print(f\" - Valores distintos: {n_distinct}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura e Análise\n",
    "\n",
    "for nome, path in datasets.items():\n",
    "    df = spark.read.option(\"header\",\"true\").csv(path)\n",
    "    qualidade_colunas(df, nome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6aca1",
   "metadata": {},
   "source": [
    "# Análise de Qualidade de Dados\n",
    "\n",
    "## Orders\n",
    "- Nenhum valor ausente nas colunas críticas (`order_id`, `customer_id`, `order_status`)\n",
    "- Valores inconsistentes foram observados em `order_status` (ex: cancelados, devolvidos)\n",
    "- Solução: Filtrar apenas pedidos entregues para análise de vendas\n",
    "\n",
    "## Order Items\n",
    "- Nenhum problema crítico\n",
    "- Valores numéricos (`price`, `freight_value`) coerentes\n",
    "\n",
    "## Customers\n",
    "- Nenhum valor ausente\n",
    "- Formatos de CEP consistentes\n",
    "- Solução: nenhuma ação necessária\n",
    "\n",
    "## Products\n",
    "- Nenhum valor ausente nas colunas principais\n",
    "- Largura, altura e peso de alguns produtos com zeros (corrigir ou ignorar na análise)\n",
    "\n",
    "## Sellers\n",
    "- Nenhum problema crítico\n",
    "\n",
    "## Reviews\n",
    "- Alguns pedidos sem review (normal)\n",
    "- Nenhum valor crítico ausente\n",
    "\n",
    "## Payments\n",
    "- Nenhum problema crítico\n",
    "- Valores coerentes\n",
    "\n",
    "## Geolocation\n",
    "- Alguns registros duplicados (mesma cidade, estado e coordenadas)\n",
    "- Não afeta análise principal\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
